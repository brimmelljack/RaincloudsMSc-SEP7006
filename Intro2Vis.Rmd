---
title: "Introduciton to Visualisating Data in RStudio"
author: "Dr. Jack Brimmell"
date: "2023-04-04"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

**Why?**

This part has two parts - 1) why use RStudio and 2) why visualise data?
First, RStudio is great. Learning R will give you skills in a widely
sought-after & transferable area (i.e., data programming), enable you to
use a free to access statistical software and put more powerful analysis
and data visualisation at your fingertips. Second, why should we
visualise our data and what does it even mean to visualise data? Here, I
mean visualising data to be a way of showing information to enable
communication, analysis, discovery and understanding (Cairo, 2016). Data
visualisation is important for understanding the true distribution of
data (i.e., whether measures of central tendency reflect the sample),
for spotting outliers, understanding trends, and for nicely showing the
results of data analyses.

**What do I want from you here?**

In a word, *nothing*. You don't have to do this at all. You can pass
your lab report to an excellent level without any of this visualisation.
But, I think we're here to gain skills and to show what we are capable
of. So, this document is designed to help you go from getting
basic bar plots you could include to more desirable and informative
raincloud plots

**What this document will not do**

This worksheet will not provide a detailed background of the layout of
RStudio. These can be found online if you wish (or email me). This
worksheet alone will not cover all of the details of what we are
actually doing with each line of code (this would make the document even
longer and potentially more off-putting).

**What do you need?**

-This RMarkdown document

-To install R and RStudio
(<https://posit.co/download/rstudio-desktop/>) - this is free

-Probably something to make notes

-Drinks & snacks (coffee and maybe alcohol depending on your coping
mechanisms)

**Final notes**

To get some nice visualisations of variables from the data set for your
lab report, you could essentially just copy and paste the code blocks
below into RStudio and press "run" - do that if you want. The examples I
perform below are not done on all variables, though. So, to be holistic
you will need to edit the code ever so slightly (e.g., change WM
accuracy variable to WM efficiency).

***Let's get going...***

The first thing we have to do is open a new script, install/load packages
(Google what is an R package), and import the MSc data file. This sounds very
simple, and some of it is (new script), but to be honest, importing data files 
is something I found tough to start with.

Let's start by creating a new script (the place you write all your code and 
run youranalyses get your visualisations). To do this just follow the image below.

![Way to start a new script](//HOLLY03/JB28$/Desktop/NewScript.jpg){width="50%"}

Now you have a blank canvas to work with. What you would do in the real world
here is write your own code. But, for this example you can copy the below 
chunks of code in to you RStudio script and run it.

You can mess around with the blank script before carrying on, if you'd like.
to write a note in the script, you start the line with a hashtag (#)

```{r - writing on a script}
#This is the start of my script - Jack 
```

If you were to write something on the script without a hashtag, R would think
it's a line of code and try to run it (and likely fail). 

The next thing to do is load our packages. Very briefly, packages are the 
bread & butter of R/RStudio and they actually do most of the work for us.
A package normally serves a particular purpose and is made up of operators,
functions, and arguments that we must satisfy in our code to get an output 
that is interpretable.

For this example we will require the tidyverse package (contains a number of
useful packages), base r (built in, doesn't need installing), and the
cowplot package.

To install these copy the below code in to your RStudio and press run. **NOTE**
becuase I already have the packages, I have used #'s here, when you copy the 
code remove the #'s before you click run!

```{r - installing packages}
#install.packages("tidyverse")
#install.packages("cowplot")
```

Just like that RStudio has downloaded lovely little packages from the 
internet. But, we ain't done there. Now we have to load them in our library.
To do this, copy and run the below code.

```{r - loading packages}
library(tidyverse)
library(cowplot)
```

OK, one last hurdle before we can start working with our data to create
some lovely plots. Loading in the data file itself. Now, I did mention that this
can be kinda tricky but it can also be fine (let's pray).

The first thing to ensure is that the data file is saved to your computer. It's
a good idea to know the pathway to the data file as this will be required. **This
is a part of the code that you will have to write yourself - but you can do it!** 

For me, this code looks like the following:

```{r - importing the Excel file (data set)}
MSc_data <- read.csv(file = "C:/Users/jb28/OneDrive - University of Bolton/R/A2-QuantDataR.csv")
head(MSc_data)
```

Let's talk about what we've done above. It looks like an easy line of code
and in some respects it was. But, it won't work for you. Making sure you read 
the file in properly is all about making sure the text in red is right. The red
text is basically a pathway to the file you want to open. In my example above
I have the data file (called A2-QuantDataR.csv) saved in a folder called "R" on
my University of Bolton OneDrive account. **So, the key thing here is knowing 
where you have saved the document you want to read in.** I like to use my
computer desktop or the OneDrive. Wherever it is, make sure you know it.

When you have read in the data file you should see the newly created object
appear in the "environment" - this is located in the top right (by default) of
the screen and contains all the objects, variables, lists & functions (Google
these if you want).

To see the newly created object, you can just click on it in the environment.
But, the other code we see here (line 130) is `head(MSc_data)` the call `head()` 
will show us a preview of the data we have just read in to R. We get the variables
in columns with the first few rows of data (6, in this case).

**NOW WE HAVE SOME DATA TO WORK WITH WOOOOO**

The next thing for us to do, is pivot this bad boy. What on Earth does that mean.

Well, the data file (remember you can click on it from the environment to see 
the full thing) is currently in what we refer to as wide format. This means that
all the information we have about a participant is contained within a single row
of the dataframe. But, when we're working with repeated measures data, or 
longitudinal data, we normally want the data in what is called long format.
A key tenet of long format is that we create a timepoint column. In this example
we have currently have two columns for each of WM accuracy, WM efficiency, 
Passing Success and Shot Creating Actions. By pivoting to long format we will
create a new column (the "Time" column) and reduced the number of WM Accuracy,
WM efficiency, Passing Success and Shot Creating Actions to just one.

**Let's do this now. The good thing (maybe...) about this part is that you can
just copy my code below to your own RStudio and run it. There are a couple of 
things to check first. One, make sure your newly created dataframe is called
'MSc_data' like mine is and make sure you read in the same file I did (the 
one available on the GitHub page: GitHub here).

```{r - changing character to numeric}
MSc_data$gender <- as.numeric(factor(MSc_data$gender))
MSc_data$level <- as.numeric(factor(MSc_data$level))
MSc_data$anx.intervention <- as.numeric(factor(MSc_data$anx.intervention))
str(MSc_data)
```

No pivoting has happened yet. But, in the above code you have changed a few 
character variables (gender, level, anx.intervention) to to numeric. The 
`str()` call shows this. The next block of code will be quite long, feel free
to just copy and paste it in to R and run it. I will explain what has 
happened on the other side of the code...see you there.

```{r - pivoting the data set}
#pivot out working memory accuracy
WM_acc <- MSc_data %>% pivot_longer(cols = starts_with("WMaccuracy"),
          names_to = "Timepoint", values_to = "WM_Accuracy") %>%
          mutate(Timepoint = gsub("WMaccuracy", "", Timepoint))
#pivot out working memory efficiency
WM_eff <- MSc_data %>% pivot_longer(cols = starts_with("WMefficiency"),
          names_to = "Timepoint", values_to = "WM_Efficiency") %>%
          mutate(Timepoint = gsub("WMefficiency", "", Timepoint))
#pivot out Passing Success
Pass <-   MSc_data %>% pivot_longer(cols = starts_with("Passing"),
          names_to = "Timepoint", values_to = "PassingSuccess") %>%
          mutate(Timepoint = gsub("PassingSuccess.", "", Timepoint))
#pivot out Shot Creating Actions
Shot <-   MSc_data %>% pivot_longer(cols = starts_with("Shot"),
          names_to = "Timepoint", values_to = "ShotCreatingActions") %>%
          mutate(Timepoint = gsub("ShotCreatingActions", "", Timepoint)) %>%
          select(-(WMaccuracy1:PassingSuccess.2))
```

The above has created four new data frames in the environment (pass, shot,
WM_acc and WM_eff) to represent the four DVs in this study. You can click in 
to any of them and you will see that for the most part, not a lot has changed.
The key thing is that each of these examples now has a "Time" variable and a 
variable of interest has been split. But, the job of pivoting longer is not 
quite done. If you look at the above code each `pivot_longer()` call is foucsed
only on one variable. What we now need to do is merge these in to one.

```{r - merging the four new dataframes}
#create a name for the new dataframe that has all the variables. I have 
#gone with MSc_long
MSc_long <- Shot %>% 
  mutate(PassSuccess = Pass$PassingSuccess) %>%
  mutate(WM_Accuracy = WM_acc$WM_Accuracy) %>%
  mutate(WM_Efficiency = WM_eff$WM_Efficiency)
head(MSc_long)
```

We now have our final dataframe and we can being to create some plots that are
great to include in our lab reports. Remember you do not have to do this (but it
will be nice).

Before we do this, the `head(MSc_long)` call above will allow you to see the 
layout of the new dataframe. You should see that each `id` now has two rows. In
each of these age, gender, level, and anx.intervention don't change. But, the
'Time' column shows the two timepoints (1 = pre intervention and 2 - post intervention).
We then see the DV (WM accuracy, WM efficiency, Passing Success and Shot Creating
Actions) variables.

let's start with a simple bar plot. I am only going to do this for one of the 
variables in each example. You can copy the code for to your own RStudio to get 
the plot the first time and then just make small amendments to get the plot 
for a new variable. I will cover how to do this briefly, but part of the fun
will be learning to do this yourself.

```{r - bar plots}
#first, let's create a simple bar plot. 
p1 <- ggplot(MSc_long, aes(x=anx.intervention, y=WM_Accuracy, fill=Timepoint)) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  theme_cowplot() +
  ggtitle("WM Accuracy Barplot") +
  ylab("Mean WM Accuracy") +
  xlab("Anxiety Group")
#for the record anxiety group 1 = control, anxiety group 2 = REBT, and 
#anxiety group 3 = self-talk
p1
```

Above is our bar plot, you can see that the anxiety group makes up the x-axis 
(1=control, 2=REBT, 3=self-talk), Mean WM accuracy is up the y-axis, and
the color bars denote the timepoints. However, from this we cannot see the 
distribution of the data nor the error or deviation from the mean.

```{r - box plots }
p2 <- ggplot(MSc_long, aes(y=WM_Accuracy, fill=Timepoint)) +
  geom_boxplot() +
  theme_cowplot() +
  ggtitle("WM Accuracy Boxplot") +
  ylab("WM Accuracy") +
  xlab("Anxiety Group") +
  facet_grid(. ~ anx.intervention) +
  scale_x_discrete(labels=c('', '', ''))
p2
```

The above is a box plot. It's a little bit better than a bar plot as we can
see more information. For example, we have the median value as the thick
black horizontal line, the box itself shows the lower (lower on the plot) &
upper (higher on the plot) quartiles, the black lines (referred to as "whiskers")
end with the minimum (lower on the plot) and maximum (higher on the plot) scores,
and finally, any black dots indicate an outlier.

But, we can level up our visualisation one more time. To do this, we're going
to build raincloud plots with ggplot2. To improve data visualisation some 
researchers have suggested plotting raw data points, to use a "split-half"
violon aesthetic, and to include a standardised visualisation of central
tendency (e.g., mean/median) and error as in a boxplot (Allen et al., 2019).

Let's create a raincloud plot for our data set below. You can copy the code
below to get an example. Remember, just like before I will not do all of the 
plots for you. You will have to mess around with the code to get all of the plots
(i.e., plots for all of the four key variables).

**Raincloud with boxplots**
```{r}
#install and load a new package - remove the hashatag on the code below
#install.packages("ggrain")
library(ggrain)

p3 <- ggplot(MSc_long, aes(x = anx.intervention, y = WM_Accuracy, fill = Timepoint)) +
  geom_rain(cov = "Timepoint", alpha = .5, boxplot.args.pos = list(width = 0.1, 
  position = position_nudge(x = .26)), violin.args.pos = list(side = "r",
  width = 1.4, position = position_nudge(x = 0.4))) +
  theme_cowplot() +
  facet_grid(. ~ anx.intervention) +
  coord_flip() +
  ggtitle("WM accuracy at two timepoints for thre anxiety interventions") +
  ylab("WM Accuracy") +
  xlab("Anxiety Group") +
  scale_x_discrete(labels=c('', '', ''))
p3
```

And there we have it, a raincloud plot for three anxiety intervention groups (
1 = control, 2 = REBT, 3 = self-talk) and two timepoints (pre and post intervention)
for the outcome variable WM accuracy. This plot has some of the best features
of the plots earlier (e.g., the box plot) alongside some of the other key 
features of a good visualisation (e.g., density plots and the raw data points).
Is the plot perfect? No. But, it's a step in the right direction and may be 
something you edit more to make even better.
Finally, you can copy this code to your own RStudio and edit it accordingly. 

***NOTE*** my last real thing to say for now is a tip for editing these to
include the other key variables (i.e., I've only ever worked with the WM
Accuracy variable and you have three others). The only thing you should need
to change to get the same three plots with the other variables is anywhere you 
see the old variables name. Do let me know if you need help with that.

**Final word** 
Thanks for taking the time to read through this, I hope it's been enjoyable
learning a new skill and if you have any questions reach out to me on 
J.Brimmell@bolton.ac.uk or on Twitter @JACKBRIMMELL.

(C) Dr. Jack Brimmell. Feel free to share with credit to original github page:
GITHUB


**References**

Allen, M., Poggiali, D., Whitaker, K., Marshall, T. R., & Kievit, R. A. (2019).
Raincloud plots: a multi-platform tool for robust data visualization.
Wellcome Open Research, 4.

Cairo, A. (2016). The truthful art: Data, charts, and maps for communication. New Riders